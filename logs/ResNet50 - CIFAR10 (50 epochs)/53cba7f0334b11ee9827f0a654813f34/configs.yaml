block_type:
  computed: <class 'torchvision.models.resnet.Bottleneck'>
  is_explicitly_specified: false
  is_hyperparam: false
  is_meta: false
  name: block_type
  options: []
  order: 0
  type: <class 'type'>
  value: <class 'torchvision.models.resnet.Bottleneck'>
block_type.bottlenecks:
  computed:
  - 64
  - 128
  - 256
  - 512
  is_explicitly_specified: false
  is_hyperparam: false
  is_meta: false
  name: block_type.bottlenecks
  options: []
  order: 1
  type: <class 'list'>
  value:
  - 64
  - 128
  - 256
  - 512
dataset_name:
  computed: CIFAR10
  is_explicitly_specified: false
  is_hyperparam: false
  is_meta: false
  name: dataset_name
  options: []
  order: 2
  type: <class 'str'>
  value: CIFAR10
device:
  computed: GPU:0 - NVIDIA GeForce RTX 4090
  is_explicitly_specified: false
  is_hyperparam: false
  is_meta: false
  name: device
  options: []
  order: 3
  type: <class 'labml_helpers.device.DeviceInfo'>
  value: GPU:0 - NVIDIA GeForce RTX 4090
epochs:
  computed: 50
  is_explicitly_specified: true
  is_hyperparam: false
  is_meta: false
  name: epochs
  options: []
  order: 20
  type: <class 'int'>
  value: 50
layer_blocks:
  computed:
  - 3
  - 4
  - 6
  - 3
  is_explicitly_specified: false
  is_hyperparam: false
  is_meta: false
  name: layer_blocks
  options: []
  order: 6
  type: <class 'list'>
  value:
  - 3
  - 4
  - 6
  - 3
loss_func:
  computed: CrossEntropyLoss()
  is_explicitly_specified: false
  is_hyperparam: false
  is_meta: false
  name: loss_func
  options: []
  order: 4
  type: <class 'torch.nn.modules.loss.CrossEntropyLoss'>
  value: CrossEntropyLoss()
model:
  computed: "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2),\
    \ padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool):\
    \ MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n\
    \  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64,\
    \ kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64,\
    \ eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2):\
    \ Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\
    \      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n\
    \      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0):\
    \ Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1):\
    \ BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1,\
    \ 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3,\
    \ 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64,\
    \ eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3):\
    \ Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3):\
    \ BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1):\
    \ Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1):\
    \ BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1),\
    \ stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n \
    \   )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256,\
    \ 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128,\
    \ eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2):\
    \ Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n\
    \      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n\
    \      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0):\
    \ Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1):\
    \ BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1,\
    \ 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3,\
    \ 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128,\
    \ eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3):\
    \ Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3):\
    \ BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1):\
    \ Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1):\
    \ BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1),\
    \ stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n \
    \   )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1),\
    \ stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3,\
    \ 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128,\
    \ eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3):\
    \ Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3):\
    \ BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0):\
    \ Bottleneck(\n      (conv1): Conv2d(512, 256 [[...]]"
  is_explicitly_specified: false
  is_hyperparam: false
  is_meta: false
  name: model
  options: []
  order: 5
  type: <class 'torchvision.models.resnet.ResNet'>
  value: "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3,\
    \ 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3,\
    \ stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n\
    \    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1,\
    \ 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3),\
    \ stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05,\
    \ momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64,\
    \ 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256,\
    \ eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu):\
    \ ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64,\
    \ 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256,\
    \ eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n \
    \   )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1),\
    \ stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3,\
    \ 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64,\
    \ eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3):\
    \ Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3):\
    \ BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1):\
    \ Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1):\
    \ BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1),\
    \ stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n \
    \   )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256,\
    \ 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128,\
    \ eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2):\
    \ Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n\
    \      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n\
    \      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0):\
    \ Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1):\
    \ BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1,\
    \ 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3,\
    \ 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128,\
    \ eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3):\
    \ Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3):\
    \ BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1):\
    \ Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1):\
    \ BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1),\
    \ stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n \
    \   )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1),\
    \ stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3,\
    \ 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128,\
    \ eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3):\
    \ Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3):\
    \ BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0):\
    \ Bottleneck(\n      (conv1): Conv2d(512, 256 [[...]]"
optimizer:
  computed: "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n\
    \    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach:\
    \ None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay:\
    \ 0.0001\n)"
  is_explicitly_specified: false
  is_hyperparam: false
  is_meta: false
  name: optimizer
  options: []
  order: 7
  type: <class 'torch.optim.adam.Adam'>
  value: "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n\
    \    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach:\
    \ None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay:\
    \ 0.0001\n)"
optimizer.adjust_lr:
  computed: false
  is_explicitly_specified: false
  is_hyperparam: false
  is_meta: false
  name: optimizer.adjust_lr
  options: []
  order: 9
  type: <class 'bool'>
  value: false
optimizer.learning_rate:
  computed: 0.001
  is_explicitly_specified: false
  is_hyperparam: false
  is_meta: false
  name: optimizer.learning_rate
  options: []
  order: 8
  type: <class 'float'>
  value: 0.001
optimizer.lr_milestones:
  computed:
  - - 0
    - 0.01
  - - 10
    - 0.1
  - - 30
    - 0.1
  - - 40
    - 0.01
  - - 50
    - 0
  is_explicitly_specified: true
  is_hyperparam: false
  is_meta: false
  name: optimizer.lr_milestones
  options: []
  order: 10
  type: <class 'list'>
  value:
  - - 0
    - 0.01
  - - 10
    - 0.1
  - - 30
    - 0.1
  - - 40
    - 0.01
  - - 50
    - 0
optimizer.lr_schedule:
  computed: <ignite.handlers.param_scheduler.PiecewiseLinear object at 0x00000114EFF9B890>
  is_explicitly_specified: true
  is_hyperparam: false
  is_meta: false
  name: optimizer.lr_schedule
  options: []
  order: 11
  type: <class 'ignite.handlers.param_scheduler.PiecewiseLinear'>
  value: <ignite.handlers.param_scheduler.PiecewiseLinear object at 0x00000114EFF9B890>
optimizer.momentum:
  computed: 0.9
  is_explicitly_specified: false
  is_hyperparam: false
  is_meta: false
  name: optimizer.momentum
  options: []
  order: 12
  type: <class 'float'>
  value: 0.9
optimizer.weight_decay:
  computed: 0.0001
  is_explicitly_specified: false
  is_hyperparam: false
  is_meta: false
  name: optimizer.weight_decay
  options: []
  order: 13
  type: <class 'float'>
  value: 0.0001
train_batch_size:
  computed: 500
  is_explicitly_specified: true
  is_hyperparam: false
  is_meta: false
  name: train_batch_size
  options: []
  order: 15
  type: <class 'int'>
  value: 500
train_dataset:
  computed: "Dataset CIFAR10\n    Number of datapoints: 50000\n    Root location:\
    \ ./data\n    Split: Train\n    StandardTransform\nTransform: Compose(\n     \
    \          RandomHorizontalFlip(p=0.5)\n               ToTensor()\n          \
    \     Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n\
    \           )"
  is_explicitly_specified: false
  is_hyperparam: false
  is_meta: false
  name: train_dataset
  options: []
  order: 14
  type: <class 'torchvision.datasets.cifar.CIFAR10'>
  value: "Dataset CIFAR10\n    Number of datapoints: 50000\n    Root location: ./data\n\
    \    Split: Train\n    StandardTransform\nTransform: Compose(\n              \
    \ RandomHorizontalFlip(p=0.5)\n               ToTensor()\n               Normalize(mean=(0.4914,\
    \ 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n           )"
train_loader_shuffle:
  computed: true
  is_explicitly_specified: false
  is_hyperparam: false
  is_meta: false
  name: train_loader_shuffle
  options: []
  order: 16
  type: <class 'bool'>
  value: true
valid_batch_size:
  computed: 500
  is_explicitly_specified: true
  is_hyperparam: false
  is_meta: false
  name: valid_batch_size
  options: []
  order: 18
  type: <class 'int'>
  value: 500
valid_dataset:
  computed: "Dataset CIFAR10\n    Number of datapoints: 10000\n    Root location:\
    \ ./data\n    Split: Test\n    StandardTransform\nTransform: Compose(\n      \
    \         ToTensor()\n               Normalize(mean=(0.4914, 0.4822, 0.4465),\
    \ std=(0.2023, 0.1994, 0.201))\n           )"
  is_explicitly_specified: false
  is_hyperparam: false
  is_meta: false
  name: valid_dataset
  options: []
  order: 17
  type: <class 'torchvision.datasets.cifar.CIFAR10'>
  value: "Dataset CIFAR10\n    Number of datapoints: 10000\n    Root location: ./data\n\
    \    Split: Test\n    StandardTransform\nTransform: Compose(\n               ToTensor()\n\
    \               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994,\
    \ 0.201))\n           )"
valid_loader_shuffle:
  computed: false
  is_explicitly_specified: false
  is_hyperparam: false
  is_meta: false
  name: valid_loader_shuffle
  options: []
  order: 19
  type: <class 'bool'>
  value: false
